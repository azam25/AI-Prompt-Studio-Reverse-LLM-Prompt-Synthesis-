<div align="center">

# ğŸš€ AI Prompt Studio

### Reverse LLM Prompt Synthesis with RLAIF Optimization

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18+-61dafb.svg)](https://reactjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-5+-blue.svg)](https://typescriptlang.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

*An intelligent prompt engineering platform that synthesizes optimal prompts from expected outputs*

[How It Works](#-reverse-llm-prompt-synthesis) â€¢ [Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture)

</div>

---

## ğŸ“‹ Overview

AI Prompt Studio implements a novel approach called **Reverse LLM Prompt Synthesis** â€” instead of manually crafting prompts and hoping for the right output, you define your **expected output format first**, and the system automatically synthesizes the optimal prompt to achieve it.

Combined with **RLAIF (Reinforcement Learning from AI Feedback)**, the platform iteratively refines prompts through an AI-driven feedback loop until they consistently produce the desired output structure and quality.

---

## ğŸ”„ Reverse LLM Prompt Synthesis

### The Problem with Traditional Prompt Engineering

```
Traditional Approach:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write Prompt â”‚ â”€â”€â–º â”‚ Run LLM     â”‚ â”€â”€â–º â”‚ Check Output     â”‚ â”€â”€â–º Repeat manually
â”‚ (guesswork)  â”‚     â”‚             â”‚     â”‚ (trial & error)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Our Reverse Synthesis Approach

```
Reverse LLM Prompt Synthesis:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Define Expected  â”‚ â”€â”€â–º â”‚ AI Synthesizes    â”‚ â”€â”€â–º â”‚ Optimized Prompt â”‚
â”‚ Output Format    â”‚     â”‚ Optimal Prompt    â”‚     â”‚ (production-ready)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RLAIF Optimization Loop   â”‚
                    â”‚  â€¢ Query Design             â”‚
                    â”‚  â€¢ Context Retrieval        â”‚
                    â”‚  â€¢ Output Generation        â”‚
                    â”‚  â€¢ Evaluation & Scoring     â”‚
                    â”‚  â€¢ Feedback Refinement      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

| Step | Process | Description |
|------|---------|-------------|
| **1** | **Define Output Template** | Specify your exact desired output format (numbered lists, bullet points, structure) |
| **2** | **Analyze Format** | System detects structure patterns, placeholders, and formatting requirements |
| **3** | **Synthesize Query** | AI generates optimal retrieval queries based on output requirements |
| **4** | **Retrieve Context** | Vector search finds relevant document chunks using FAISS embeddings |
| **5** | **Generate Prompt** | Creates ChatML prompt designed to produce the expected output format |
| **6** | **Evaluate & Score** | AI evaluates if generated output matches expected structure |
| **7** | **Refine (RLAIF)** | Uses feedback to improve query and prompt design iteratively |
| **8** | **Select Best** | Returns the highest-scoring prompt across all iterations |

### Key Innovation

> **Traditional**: *"How do I write a prompt to get X?"*  
> **Reverse Synthesis**: *"This is X, synthesize the prompt that produces it."*

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ“„ **Multi-Format Document Upload** | Support for PDF, DOCX, TXT, and Markdown files |
| ğŸ§  **Vector Embeddings** | FAISS-powered semantic search for intelligent context retrieval |
| ğŸ¯ **Template-Based Output** | Define exact output structure with placeholders or numbered formats |
| ğŸ”„ **RLAIF Optimization Loop** | Iterative prompt refinement with AI-powered evaluation (3-5 iterations) |
| ğŸ“Š **Best Iteration Selection** | Automatically selects the highest-scoring iteration |
| ğŸ§ª **Prompt Testing** | Test generated prompts directly in the UI |
| ğŸ“‹ **ChatML Export** | Production-ready prompts in OpenAI-compatible JSON format |
| âš™ï¸ **Configurable LLM Settings** | Customize model, temperature, and max tokens |
| ğŸ“ **Output Instructions** | Specify response style (concise, detailed, bullet points) |

---

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.9+
- Node.js 18+
- OpenAI API key (or compatible API)

### Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # macOS/Linux
pip install -r requirements.txt
python run.py
```

Backend: `http://localhost:8000`

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend: `http://localhost:5173`

---

## ğŸš€ Usage

### 1ï¸âƒ£ Configure LLM
Click âš™ï¸ **Settings** â†’ Enter API Key, Model, Temperature

### 2ï¸âƒ£ Upload Documents
Drag & drop PDF, DOCX, TXT, or MD files

### 3ï¸âƒ£ Define Expected Output
```
Required Technology Stack:
1. List of required software
2. List of required tools
3. Cloud or SaaS platforms
4. Other technical requirements
```

### 4ï¸âƒ£ Add Output Instructions (Optional)
```
- Be concise and specific
- Use bullet points
- No citations
```

### 5ï¸âƒ£ Generate & Test
Click **âš¡ Generate Prompt** â†’ **ğŸ§ª Test** â†’ **ğŸ’¾ Export**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Prompt Studio                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend (React + TypeScript + Vite)                           â”‚
â”‚  â”œâ”€â”€ Document Upload                                             â”‚
â”‚  â”œâ”€â”€ Expected Output Editor                                      â”‚
â”‚  â”œâ”€â”€ Optimization Progress                                       â”‚
â”‚  â””â”€â”€ Prompt Result & Testing                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend (FastAPI + Python)                                      â”‚
â”‚  â”œâ”€â”€ Document Processor       - Parse multi-format documents    â”‚
â”‚  â”œâ”€â”€ Vector Store (FAISS)     - Semantic embeddings & search    â”‚
â”‚  â”œâ”€â”€ Query Designer           - Synthesize retrieval queries    â”‚
â”‚  â”œâ”€â”€ Evaluation LLM           - Score output quality            â”‚
â”‚  â”œâ”€â”€ RLAIF Optimizer          - Iterative refinement loop       â”‚
â”‚  â””â”€â”€ ChatML Formatter         - OpenAI-compatible export        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Reverse Synthesis Flow

```mermaid
graph TD
    A[Expected Output Template] --> B[Analyze Structure]
    B --> C[Synthesize Query]
    C --> D[Retrieve Context]
    D --> E[Generate Prompt]
    E --> F[Evaluate Output]
    F --> G{Score â‰¥ Threshold?}
    G -->|Yes| H[Return Best Prompt]
    G -->|No| I[RLAIF Feedback]
    I --> C
```

---

## ğŸ“ Project Structure

```
AIPromptStudio/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/      # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ models/          # Pydantic models
â”‚   â”‚   â””â”€â”€ services/        # Core synthesis logic
â”‚   â”‚       â”œâ”€â”€ query_designer.py      # Query synthesis
â”‚   â”‚       â”œâ”€â”€ rlaif_optimizer.py     # RLAIF loop
â”‚   â”‚       â”œâ”€â”€ evaluation_llm.py      # Output scoring
â”‚   â”‚       â””â”€â”€ chatml_formatter.py    # Prompt formatting
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/      # React UI components
â”‚       â””â”€â”€ services/        # API client
â””â”€â”€ README.md
```

---

## ğŸ“¡ API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/config/llm` | GET/POST | Get/Update LLM configuration |
| `/api/documents/upload` | POST | Upload document for processing |
| `/api/prompts/optimize` | POST | Run Reverse LLM Prompt Synthesis |
| `/api/prompts/test` | POST | Test synthesized prompt |
| `/api/prompts/export` | POST | Export in ChatML format |

---

## âš™ï¸ Environment Variables

```env
# backend/.env
OPENAI_API_KEY=your_api_key
OPENAI_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-ada-002
TEMPERATURE=0.7
MAX_TOKENS=2000
MIN_OPTIMIZATION_ITERATIONS=3
MAX_OPTIMIZATION_ITERATIONS=5
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

---

<div align="center">

**Reverse LLM Prompt Synthesis** â€” *Define the output, synthesize the prompt*

â­ **Star this repo if you find it useful!**

</div>
